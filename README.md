# MLOps Project: Abalone Age Prediction - Complete Setup Guide

<div align="center">

[![Python Version](https://img.shields.io/badge/python-3.10%20or%203.11-blue.svg)]()
[![Docker](https://img.shields.io/badge/docker-enabled-blue.svg)]()
[![Prefect](https://img.shields.io/badge/prefect-workflow-green.svg)]()
[![MLflow](https://img.shields.io/badge/mlflow-tracking-orange.svg)]()

</div>

## ğŸ¯ Project Overview

This MLOps project builds a complete machine learning system to predict the age of abalone (a type of sea snail) using physical measurements instead of the traditional time-consuming method of counting shell rings under a microscope.

**Mission**: Transform a simple ML model into a production-ready system with automated training, deployment, and prediction capabilities.

## ğŸš€ Quick Start with Docker (Recommended)

### Prerequisites
- Docker and Docker Compose installed
- Git (to clone the repository)

### 1. Clone and Setup
```bash
git clone <your-repo-url>
cd xhec-mlops-2025-project
```

### 2. Start All Services
```bash
docker compose up --build
```

### 3. Access the Services
- **FastAPI API**: http://localhost:8000
- **Prefect UI**: http://localhost:4200
- **MLflow UI**: http://localhost:5000

## ğŸ³ Docker Services Overview

### ğŸŒ **FastAPI Prediction API** (Port 8000)
- **Purpose**: REST API for making abalone age predictions
- **Endpoints**:
  - `GET /` - Health check
  - `POST /predict` - Make predictions
  - `POST /deploy` - Launch Prefect deployment

### ğŸ“Š **Prefect Workflow Management** (Port 4200)
- **Purpose**: Orchestrate and monitor ML training workflows
- **Features**: Deployment management, run monitoring, scheduling

### ğŸ”¬ **MLflow Experiment Tracking** (Port 5000)
- **Purpose**: Track experiments, log metrics, manage model versions
- **Features**: Experiment comparison, model registry, artifact storage

## ğŸ“ Using the FastAPI API

### Health Check
```bash
curl http://localhost:8000/
```

### Make Predictions
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "Sex": "M",
    "Diameter": 0.35,
    "Height": 0.105,
    "Whole_weight": 0.2255,
    "Shucked_weight": 0.0995,
    "Viscera_weight": 0.0485,
    "Shell_weight": 0.07
  }'
```

### Launch Model Retraining
```bash
curl -X POST "http://localhost:8000/deploy?data_path=data/abalone.csv"
```

## ğŸ”„ Running Prefect Workflows Locally

### Prerequisites for Local Development
- Python 3.10 or 3.11
- Virtual environment setup

### 1. Initial Project Setup
This project is already configured with:
- âœ… **Dependencies**: All required packages in `pyproject.toml`
- âœ… **Code Quality**: Pre-commit hooks configured
- âœ… **CI/CD**: GitHub Actions workflow for automated checks

### 2. Setup Local Environment
```bash
# Create virtual environment
uv sync
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install pre-commit hooks
uv run pre-commit install
```

### 2. Start Prefect Server Locally
```bash
# Terminal 1: Start Prefect server
prefect server start --host 0.0.0.0 --port 4201
```

### 3. Access Prefect UI
- Open http://localhost:4201 in your browser

### 4. Run Training Workflow Locally

#### Data Path Options
The training workflow accepts data paths in three formats:

1. **No path specified** (uses default):
   ```bash
   uv run python -m src.modelling.deployment
   # Uses: data/abalone.csv (default)
   ```

2. **Relative path** (relative to project root):
   ```bash
   uv run python -m src.modelling.deployment data/abalone.csv
   uv run python -m src.modelling.deployment data/my_dataset.csv
   ```

3. **Absolute path** (full system path):
   ```bash
   uv run python -m src.modelling.deployment /home/user/datasets/abalone.csv
   uv run python -m src.modelling.deployment /Users/student/Downloads/data.csv
   ```

**âš ï¸ Important**: Absolute paths will **NOT work in Docker** because the container has its own filesystem. For Docker usage, always use relative paths or place data in the `data/` folder.

**ğŸ’¡ Recommendation**: Place your data files in the `data/` folder for easy access and consistency.

#### Option A: Direct Python Execution
```bash
# From project root
cd src/modelling
uv run python main.py ../../data/abalone.csv
```

#### Option B: Using Prefect Deployment
```bash
# From project root
uv run python -m src.modelling.deployment data/abalone.csv
```

### 5. Monitor Training Progress
- Check Prefect UI at http://localhost:4201
- View MLflow experiments at http://localhost:5000

## ğŸ§ª Testing the Complete Pipeline

### 1. Test Prediction API
```bash
# Test with sample data
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "Sex": "F",
    "Diameter": 0.45,
    "Height": 0.15,
    "Whole_weight": 0.5,
    "Shucked_weight": 0.25,
    "Viscera_weight": 0.1,
    "Shell_weight": 0.15
  }'
```

### 2. Test Model Retraining
```bash
# Trigger retraining via API
curl -X POST "http://localhost:8000/deploy?data_path=data/abalone.csv"

# Check Prefect UI for deployment status
# Check MLflow for new experiment runs
```

### 3. Verify Model Updates
- Check `src/web_service/local_objects/` for updated `model.pkl` and `encoder.pkl`
- Test predictions with new model

## ğŸ“Š Data Format

### Input Data Schema
```json
{
  "Sex": "M|F|I",           // Sex: Male, Female, or Infant
  "Diameter": 0.35,         // Shell diameter (mm)
  "Height": 0.105,          // Shell height (mm)
  "Whole_weight": 0.2255,   // Whole weight (grams)
  "Shucked_weight": 0.0995, // Shucked weight (grams)
  "Viscera_weight": 0.0485, // Viscera weight (grams)
  "Shell_weight": 0.07      // Shell weight (grams)
}
```

### Expected Output
```json
{
  "predicted_rings": 8.5    // Predicted number of rings (age)
}
```


## ğŸ“ Project Structure

```
xhec-mlops-2025-project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ modelling/          # ML training pipeline
â”‚   â”‚   â”œâ”€â”€ main.py         # Prefect training flow
â”‚   â”‚   â”œâ”€â”€ deployment.py   # Prefect deployment script
â”‚   â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”‚   â”œâ”€â”€ training.py
â”‚   â”‚   â”œâ”€â”€ predicting.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â””â”€â”€ web_service/        # FastAPI application
â”‚       â”œâ”€â”€ main.py         # FastAPI app
â”‚       â”œâ”€â”€ utils.py        # Utility functions
â”‚       â”œâ”€â”€ lib/
â”‚       â”‚   â”œâ”€â”€ models.py   # Pydantic models
â”‚       â”‚   â””â”€â”€ inference.py # Prediction logic
â”‚       â””â”€â”€ local_objects/  # Model storage
â”œâ”€â”€ data/
â”‚   â””â”€â”€ abalone.csv        # Training data
â”œâ”€â”€ docker-compose.yml     # Docker services
â”œâ”€â”€ Dockerfile            # Container definition
â””â”€â”€ bin/
    â””â”€â”€ run_services.sh   # Service startup script
```

## ğŸ¯ Key Features

- âœ… **Automated ML Pipeline**: Prefect-based workflow orchestration
- âœ… **REST API**: FastAPI for real-time predictions
- âœ… **Experiment Tracking**: MLflow integration
- âœ… **Containerized Deployment**: Docker-based deployment
- âœ… **Model Versioning**: Automatic model updates
- âœ… **Health Monitoring**: API health checks and monitoring

---

**Happy MLOps! ğŸ‰**
