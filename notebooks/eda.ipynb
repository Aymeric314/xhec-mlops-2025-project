{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (Exploratory Data Analysis) of the dataset\n",
    "\n",
    "In this notebook, explore the Abalone dataset, by showing relevant visualizations that help understand the problem you are modelling.\n",
    "\n",
    "Please make sure to write down your conclusions in the final notebook and to remove these intructions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple, Any, Optional"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/abalone.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_summary(df: pd.DataFrame, n_top: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"Create a concise summary table for a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe to summarise.\n",
    "    n_top : int, optional\n",
    "        Number of top values to consider for the \"top\" value detection (unused but kept for API parity), by default 5\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Summary DataFrame with columns:\n",
    "        - column: column name\n",
    "        - dtype: dtype as string\n",
    "        - n_missing: number of missing values\n",
    "        - pct_missing: fraction of missing values (0..1)\n",
    "        - n_unique: number of unique non-null values\n",
    "        - top: most frequent non-null value (or None)\n",
    "        - top_count: count of the most frequent value (0 if none)\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function does not modify the input DataFrame.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"df must be a pandas DataFrame\")\n",
    "\n",
    "    rows = []\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "        non_null = series.dropna()\n",
    "        top_val = non_null.mode().iloc[0] if not non_null.empty else None\n",
    "        top_count = int(non_null.value_counts().iloc[0]) if not non_null.empty else 0\n",
    "        rows.append({\n",
    "            \"column\": col,\n",
    "            \"dtype\": str(series.dtype),\n",
    "            \"n_missing\": int(series.isna().sum()),\n",
    "            \"pct_missing\": float(series.isna().mean()),\n",
    "            \"n_unique\": int(series.nunique(dropna=True)),\n",
    "            \"top\": top_val,\n",
    "            \"top_count\": top_count,\n",
    "        })\n",
    "    result = pd.DataFrame(rows).sort_values(\"pct_missing\", ascending=False).reset_index(drop=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "def missing_summary(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Return a Series with counts of missing values for columns with any missing values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Series indexed by column name with integer counts of missing values, sorted descending.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"df must be a pandas DataFrame\")\n",
    "    miss = df.isna().sum()\n",
    "    miss = miss[miss > 0].sort_values(ascending=False)\n",
    "    return miss\n",
    "\n",
    "\n",
    "def summary_statistics(df: pd.DataFrame, numeric_cols: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"Compute descriptive statistics plus skewness and kurtosis for numeric columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    numeric_cols : list[str] | None\n",
    "        List of numeric column names to include. If None, all numeric columns are used.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Table of descriptive statistics (count, mean, std, min, 25%, 50%, 75%, max) with added columns\n",
    "        'skew' and 'kurt' indexed by column name.\n",
    "    \"\"\"\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"df must be a pandas DataFrame\")\n",
    "    if numeric_cols is None:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not numeric_cols:\n",
    "        return pd.DataFrame()\n",
    "    stats = df[numeric_cols].describe().T\n",
    "    stats['skew'] = df[numeric_cols].skew()\n",
    "    stats['kurt'] = df[numeric_cols].kurt()\n",
    "    return stats\n",
    "\n",
    "\n",
    "def plot_numeric_distributions(df: pd.DataFrame,\n",
    "                               numeric_cols: Optional[List[str]] = None,\n",
    "                               bins: int = 30,\n",
    "                               figsize: Tuple[int, int] = (12, 8)) -> None:\n",
    "    \"\"\"Plot histograms and boxplots for numeric columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    numeric_cols : list[str] | None\n",
    "        Columns to plot. If None, selects all numeric columns.\n",
    "    bins : int\n",
    "        Number of bins for histograms.\n",
    "    figsize : tuple\n",
    "        Figure size for the full figure.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Displays matplotlib plots inline. Does not return a value.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - For many numeric columns, this will create multiple subplots; consider selecting a subset.\n",
    "    \"\"\"\n",
    "    if numeric_cols is None:\n",
    "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not numeric_cols:\n",
    "        print(\"No numeric columns found to plot.\")\n",
    "        return\n",
    "\n",
    "    n = len(numeric_cols)\n",
    "    cols = min(3, n)\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    fig, axes = plt.subplots(rows * 2, cols, figsize=figsize)\n",
    "    # Normalize axes shape\n",
    "    axes = np.array(axes).reshape(rows * 2, cols)\n",
    "    for i, col in enumerate(numeric_cols):\n",
    "        r = (i // cols) * 2\n",
    "        c = i % cols\n",
    "        sns.histplot(df[col].dropna(), bins=bins, ax=axes[r, c], kde=True)\n",
    "        axes[r, c].set_title(f\"Histogram: {col}\")\n",
    "        sns.boxplot(x=df[col], ax=axes[r + 1, c])\n",
    "        axes[r + 1, c].set_title(f\"Boxplot: {col}\")\n",
    "    # hide unused axes\n",
    "    for j in range(i + 1, rows * cols):\n",
    "        r = (j // cols) * 2\n",
    "        c = j % cols\n",
    "        axes[r, c].set_visible(False)\n",
    "        axes[r + 1, c].set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def correlation_matrix(df: pd.DataFrame,\n",
    "                       numeric_only: bool = True,\n",
    "                       figsize: Tuple[int, int] = (10, 8),\n",
    "                       method: str = 'pearson') -> pd.DataFrame:\n",
    "    \"\"\"Compute and plot a correlation matrix for numeric columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    numeric_only : bool\n",
    "        If True, compute correlations on numeric columns only.\n",
    "    figsize : tuple\n",
    "        Figure size for the heatmap.\n",
    "    method : str\n",
    "        Correlation method passed to `pandas.DataFrame.corr` (e.g., 'pearson', 'spearman').\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The correlation matrix (DataFrame).\n",
    "    \"\"\"\n",
    "    if numeric_only:\n",
    "        df_num = df.select_dtypes(include=[np.number])\n",
    "    else:\n",
    "        df_num = df.copy()\n",
    "    corr = df_num.corr(method=method)\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', square=True)\n",
    "    plt.title('Correlation matrix')\n",
    "    plt.show()\n",
    "    return corr\n",
    "\n",
    "\n",
    "def categorical_summary(df: pd.DataFrame, cat_cols: Optional[List[str]] = None, top_n: int = 10) -> Dict[str, pd.Series]:\n",
    "    \"\"\"Return value counts for categorical columns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    cat_cols : list[str] | None\n",
    "        Columns to treat as categorical. If None, object and category dtypes are used.\n",
    "    top_n : int\n",
    "        When displaying, how many top categories to show (function returns full counts).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping column name -> pandas Series of value counts (including NaN if present).\n",
    "    \"\"\"\n",
    "    if cat_cols is None:\n",
    "        cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    result: Dict[str, pd.Series] = {}\n",
    "    for c in cat_cols:\n",
    "        result[c] = df[c].value_counts(dropna=False)\n",
    "    return result\n",
    "\n",
    "\n",
    "def detect_outliers(df: pd.DataFrame, col: str, method: str = 'iqr') -> pd.Series:\n",
    "    \"\"\"Detect outliers in a numeric column and return a boolean mask.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    col : str\n",
    "        Column name to check for outliers.\n",
    "    method : {'iqr', 'zscore'}\n",
    "        Detection method. 'iqr' flags values outside 1.5*IQR from Q1/Q3. 'zscore' flags |z| > 3.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Boolean mask indexed like `df[col]` where True indicates an outlier.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "        If `col` is not in `df`.\n",
    "    ValueError\n",
    "        If `method` is unsupported.\n",
    "    \"\"\"\n",
    "    if col not in df.columns:\n",
    "        raise KeyError(f\"Column '{col}' not found in dataframe\")\n",
    "    if not pd.api.types.is_numeric_dtype(df[col]):\n",
    "        raise TypeError(f\"Column '{col}' must be numeric for outlier detection\")\n",
    "\n",
    "    series = df[col]\n",
    "    if method == 'iqr':\n",
    "        q1 = series.quantile(0.25)\n",
    "        q3 = series.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        lower = q1 - 1.5 * iqr\n",
    "        upper = q3 + 1.5 * iqr\n",
    "        mask = (series < lower) | (series > upper)\n",
    "    elif method == 'zscore':\n",
    "        from scipy import stats\n",
    "        z = np.abs(stats.zscore(series.fillna(series.mean())))\n",
    "        mask = pd.Series(z > 3, index=series.index)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'iqr' or 'zscore'\")\n",
    "    return mask\n",
    "\n",
    "\n",
    "def top_feature_correlations(df: pd.DataFrame, target_col: str, top_n: int = 5) -> List[Tuple[str, float]]:\n",
    "    \"\"\"Return the top features most (absolute) correlated with the numeric target column.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    target_col : str\n",
    "        Name of the numeric target column.\n",
    "    top_n : int\n",
    "        Number of top features to return.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of (feature, abs_correlation)\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "        If `target_col` not found.\n",
    "    TypeError\n",
    "        If `target_col` is not numeric.\n",
    "    \"\"\"\n",
    "    if target_col not in df.columns:\n",
    "        raise KeyError(f\"{target_col} not in dataframe\")\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        raise TypeError(f\"{target_col} must be numeric\")\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    corr = df[num_cols].corr()[target_col].drop(index=target_col).abs().sort_values(ascending=False)\n",
    "    return list(corr.head(top_n).items())\n",
    "\n",
    "\n",
    "def pairplot_preview(df: pd.DataFrame, cols: Optional[List[str]] = None, sample_frac: float = 0.2, height: float = 2.5) -> None:\n",
    "    \"\"\"Display a seaborn pairplot for selected columns using a sampled subset for speed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe.\n",
    "    cols : list[str] | None\n",
    "        Columns to include in the pairplot. If None, uses numeric columns.\n",
    "    sample_frac : float\n",
    "        Fraction to sample (0 < sample_frac <= 1). If 1, uses full data.\n",
    "    height : float\n",
    "        Height parameter passed to seaborn.pairplot.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Shows the plot inline.\n",
    "    \"\"\"\n",
    "    if cols is None:\n",
    "        cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if not cols:\n",
    "        print(\"No columns selected for pairplot\")\n",
    "        return\n",
    "    if sample_frac is not None and 0 < sample_frac < 1.0:\n",
    "        dfp = df[cols].sample(frac=sample_frac, random_state=0)\n",
    "    else:\n",
    "        dfp = df[cols]\n",
    "    sns.pairplot(dfp, diag_kind='kde', height=height)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def target_analysis(df: pd.DataFrame, target_col: str) -> None:\n",
    "    \"\"\"\n",
    "    Show distribution and relationship with numeric features for a regression target.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe containing the target and features.\n",
    "    target_col : str\n",
    "        Name of the numeric target column to analyse.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Displays descriptive statistics, a histogram of the target, and a correlation series\n",
    "        between the target and numeric features (displayed in the notebook).\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    KeyError\n",
    "        If `target_col` is not present in `df`.\n",
    "    TypeError\n",
    "        If `target_col` is not numeric.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - This function displays plots inline (matplotlib / seaborn) and uses pandas `display`\n",
    "      for tabular output. It does not return values programmatically.\n",
    "    \"\"\"\n",
    "\n",
    "    if target_col not in df.columns:\n",
    "        raise KeyError(f\"Target column '{target_col}' not found in dataframe\")\n",
    "    if not pd.api.types.is_numeric_dtype(df[target_col]):\n",
    "        raise TypeError(f\"Target column '{target_col}' must be numeric\")\n",
    "\n",
    "    print(f\"Target: {target_col}\")\n",
    "    display(df[target_col].describe())\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df[target_col].dropna(), kde=True)\n",
    "    plt.title(f\"Distribution of {target_col}\")\n",
    "    plt.xlabel(target_col)\n",
    "    plt.show()\n",
    "\n",
    "    # relationship with numeric features\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    num_cols = [c for c in num_cols if c != target_col]\n",
    "    if len(num_cols) > 0:\n",
    "        corr = df[num_cols + [target_col]].corr()[target_col].sort_values(ascending=False)\n",
    "        display(corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Profile summary (table)\n",
    "profile_df = profile_summary(df)\n",
    "display(profile_df.head(50))\n",
    "\n",
    "# 2) Descriptive statistics (with skew/kurtosis)\n",
    "stats = summary_statistics(df)\n",
    "display(stats)\n",
    "\n",
    "# 3) Numeric distributions (plots will render inline)\n",
    "plot_numeric_distributions(df)\n",
    "\n",
    "# 4) Correlation matrix (returns DataFrame and plots heatmap)\n",
    "corr = correlation_matrix(df)\n",
    "display(corr)\n",
    "\n",
    "# 5) Target analysis (replace 'Rings' if your target column has another name)\n",
    "target_col = \"Rings\"\n",
    "if target_col in df.columns:\n",
    "    target_analysis(df, target_col)\n",
    "    top_feats = top_feature_correlations(df, target_col, top_n=10)\n",
    "    print(\"Top correlations with target (abs):\", top_feats)\n",
    "else:\n",
    "    print(f\"Target column '{target_col}' not found; skip target-specific analysis.\")\n",
    "\n",
    "# 6) Pairplot preview for selected numeric columns (sample fraction avoids huge plots)\n",
    "numeric_cols = df.select_dtypes(include=[float, int]).columns.tolist()\n",
    "# choose a short list to keep pairplot readable, fallback to first 4 numeric cols\n",
    "pair_cols = numeric_cols[:4] if len(numeric_cols) >= 4 else numeric_cols\n",
    "pairplot_preview(df, cols=pair_cols, sample_frac=0.2)\n",
    "\n",
    "# 7) Outlier detection example on target or another numeric column\n",
    "example_col = target_col if target_col in df.columns else (numeric_cols[0] if numeric_cols else None)\n",
    "if example_col:\n",
    "    mask = detect_outliers(df, col=example_col, method='iqr')\n",
    "    print(f\"Outliers in {example_col}: {int(mask.sum())}\")\n",
    "    display(df.loc[mask])\n",
    "else:\n",
    "    print(\"No numeric column available for outlier detection.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and next steps\n",
    "\n",
    "### Function-by-function notes\n",
    "\n",
    "- `profile_summary(df)`\n",
    "  - Purpose: quick column-level inventory (dtypes, missing counts, unique counts, most frequent values).\n",
    "  - How we used it: verified there are only a few columns with missing data and that most features are numeric. The `top`/`top_count` fields helped detect any dominant categorical values.\n",
    "  - Impact: informed a conservative imputation approach (mean for numeric, mode for categorical) for columns with low missingness.\n",
    "\n",
    "- `missing_summary(df)`\n",
    "  - Purpose: concise list of columns with missing values and their counts.\n",
    "  - How we used it: identified which columns need imputation and whether missingness is widespread or limited to a few features.\n",
    "  - Impact: No mising values so need to consider any imputation.\n",
    "\n",
    "- `summary_statistics(df)`\n",
    "  - Purpose: descriptive statistics plus skew/kurtosis for numeric features.\n",
    "  - How we used it: inspected means, medians and skewness to identify non-normal features and potential need for transformations.\n",
    "  - Impact: noted the target (Rings) and some predictors are skewed — consider transform only if it improves model residuals.\n",
    "\n",
    "- `plot_numeric_distributions(df, ...)`\n",
    "  - Purpose: visual check (histograms + boxplots) for numeric features.\n",
    "  - How we used it: visually inspected distributions and the presence of extreme values.\n",
    "  - Impact: confirmed presence of many extreme values (outliers) across several numeric columns.\n",
    "\n",
    "- `correlation_matrix(df)` and `top_feature_correlations(df, target_col)`\n",
    "  - Purpose: measure linear relationships between numeric features and with the target.\n",
    "  - How we used it: identified pairs of highly correlated features and ranked predictors by absolute correlation with the target.\n",
    "  - Impact: discovered `Length` and `Diameter` are highly correlated (near-duplicate information). To avoid redundancy and potential multicollinearity in linear models, we decided to drop `Length` and keep `Diameter` as the representative feature.\n",
    "\n",
    "- `pairplot_preview(df, cols=...)`\n",
    "  - Purpose: pairwise scatter and density plots for small sets of features.\n",
    "  - How we used it: validated linear relationships and non-linear patterns between the target and candidate predictors.\n",
    "  - Impact: helped confirm the `Length`/`Diameter` redundancy visually\n",
    "\n",
    "- `categorical_summary(df)`\n",
    "  - Purpose: value counts for categorical columns.\n",
    "  - How we used it: assessed cardinality and whether one-hot or ordinal encoding is appropriate.\n",
    "  - Impact: low-cardinality categoricals will be one-hot encoded; if high-cardinality appears later we will use target or frequency encoding.\n",
    "\n",
    "- `detect_outliers(df, col, method='iqr')` and overall outlier handling\n",
    "  - Purpose: flag values that are extreme according to IQR or z-score rules.\n",
    "  - How we used it: measured how many rows would be flagged as outliers for each numeric column.\n",
    "  - Impact (final decision): although many columns contain extreme values, the number of flagged rows is large and appears to reflect the natural variability of the dataset rather than measurement error. Therefore we decided to *keep* outliers for modelling rather than removing them, and to prefer robust models (tree-based) or robust scorers if necessary. If a model performs poorly because of extreme values, we will revisit this decision and consider targeted winsorization or transformations for specific features.\n",
    "\n",
    "\n",
    "### Concrete preprocessing decisions made from the EDA\n",
    "\n",
    "1. Keep outliers: many rows are flagged across features, and the distribution of the target/variables suggests the extremes are real observations. We will keep them for now and rely on robust modeling choices (tree-based models, robust scalers) or reconsider targeted clipping if a particular model shows sensitivity.\n",
    "\n",
    "2. Drop `Length`: `Length` and `Diameter` were found to be highly correlated (almost redundant). To reduce multicollinearity and simplify the feature set we remove `Length` and keep `Diameter` as the representative geometric dimension.\n",
    "\n",
    "3. Encoding and scaling: one-hot encode low-cardinality categoricals; for numeric features, scale only for models that require it (standard scaling for linear models; tree-based models can be used without scaling)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xhec-mlops-project-student",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
